#### Основы
*Необходимая информация для дальнейший терминов.*

***

- **Частота**: количество отобранных элементов
- **Отклонение** - Разность выбранного элемента с средним значением ![deviation!](/theory/img/otklonenie.png)
- **Дисперсия** - сумма квадратов отклонений, деленное на их количество
    - $\delta$ - отклонение, тогда: $D=\frac{\sum_{i=1}^{i=n}\delta_i^2}{n}$
- **Среднеквадратическое отклонение** - корень дисперсии
    - $\sigma=\sqrt{\frac{\sum_{i=1}^{i=n}\delta_i^2}{n}}$

***

#### main

1. **Генеральная совокупность** - *все* элементы
2. **Выборка** - группа элементов из **генеральной совокупности**
3. **Репрезентативность** - степень похожести выборкы на генеральную совокупность

***

#### Нормальное распределение

- **Закон распределения случайной величины***(функция распределения случайной величины $F(x)$)*: *вероятность* того, что *случайная величина примит значения меньше* $x$: $F(x) = P(\xi < x)$  
- **Плотность распределения $f(x)$**:  $f(x) = F'(x)$ *иногда функцию плотности и называют законом распределения*, с помощью функции плотности удобно находить вероятность попадания случайной величины в диапазон: $P(\alpha < \xi < \beta) = \int_{\alpha}^{\beta}f(x)dx$ 
- **график плотности**:
  - ![func, plotnost!](/theory/img/plotnost(func).png)
  - зависимость идет частоты от величины, тогда $\frac{f_i}{\sum f_i} = w_i \sim P_i$ где $ w_i $ - статистический вес, что аналог вероятности
- Площадь под кривой функции плотности распределения равна единице. 
  - *Вытянутось графика зависит от **среднеквадратичного отклонения*** 
  - ![addiction_sigma!](/theory/img/addiction.png)
- формула плотности: $f(x)=\frac{1}{\sigma \sqrt{2\pi}}e^{-\frac{(x-a)^2}{2\sigma^2}}$
- Для расчета *функции распределения случайной велоичины* возьмем интеграл от функции плотности - это не берущийся интегралл вида : $F(x) = \frac{1}{\sigma \sqrt{2\pi}}\int_{-\infty}^{\frac{x-m}{\sigma}}e^{-\frac{t^2}{2}}\sigma dt$ - это неберщийся интеграл. Считаем приближенно, этот интеграл называют **функцией Лапласа**. Далее получаем функцию в интервале от $от 0 до 1$, произведем *нормирование функции Лапаса* : подставим $m=0, \sigma=1$ и изобразим график с сдвигом вниз на 0.5:
  - ![laplass!](/theory/img/laplass.png)

***

#### Гипотеза

По сути статистика занимается проверкой гипотез. *Гипотеза* - предположение основанное на чем-либо и требующие доказательства. Рассмотрим на примере:

Из *генеральной совокупности* дибетиков мы возьмем *выборку* пациентов и проведем на ней исследования.  
По результатам иследований получим зависимость например степени выраженности лекарства от дозы:
- ![issledovanie!](/theory/img/Gipotezy_issled.png)  
Есть вероятность, что при большой *выборке* из той же *генеральной совокупности* зависимость сильно поменяется:
- ![more!](/theory/img/Gipotezy_add_more.png)  
Как понять - есть ли зависимость ?  
Выдвигается **нулевая гипотеза** - которая формулируется от обратного, то есть отвергает зависимость: *Взаимосвязь между дозой и эффектом отсутствует*.  
Далее у нас есть 4 варианта:  
- Принять *верную* нулевую гипотезу
- Отвергнуть *верную* нулевую гипотезу - ***ошибка***
  - Вероятность такой ошибки - $\alpha$, её называют *ошибкой первого рода*
  - **P уровень значимости** - вероятность *ошибки первого рода*.
- Принять **не***верную* нулевую гипотезу
- Отвергнуть **не***верную* нулевую гипотезу - ***ошибка***
  - Вероятность такой ошибки - $\beta$, её называют *ошибкой второго рода*
  - Через $\beta$ обычно вычисляют **мощность** исследования, которая равна $1-\beta$

Итого у нас имеется определение **статистической значимости $P$**:  
> $P$: расчетная вероятность ошибки первого рода.

*Статистически значимым* считается уровень значимости меньше критического уровня $P$, например $P < 0.05$  
Если в исследовании **уровень значимости** оказался больше (***в книги почему то меньше, я уже ничего не понимаю помогите***) *критического уровня значимости, то нуль гипотеза отвергается и принимается **альтернативная** гипотеза.  

***

#### Критерий

**Статистический критерий** - строгое мат. правило, по которому принимается или отвергается та или иная статистическая гипотеза известным уровнем значимости.

***

#### Статистическая зависимость

**Статистическая зависимость** — это связь двух случайных величин, при которой распределение вероятностей одной из них зависит от того, какие возможные значения приняла другая величина.

Если случайные величины зависимы, то изменения значений одной или нескольких из этих величин приводят к систематическому изменению значений другой (или других) величин.

Статистическая зависимость двух переменных – обобщение функциональной зависимости. В этом случае одному и тому же значению $x$ могут соответствовать разные значения $y$.  
Например, если $x$ — число посетителей супермаркета за день, а $y$ — объём продаж, то даже при одинаковом числе посетителей продажи будут разными.  